{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef7725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ada18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import fnmatch\n",
    "pd.set_option('max_colwidth', None)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3264630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\08 - data engineering\\Data Drops\\P.TTOK.CONT\\TPA Automatization proccess\"\n",
    "\n",
    "#[filename for filename in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d3f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\37. New DP Data\\BPO_QUEUE_DAILY\"\n",
    "path4 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\37. New DP Data\\BPO_QUEUE_VMS\"\n",
    "path2 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\37. New DP Data\\INTEGRITY\"\n",
    "path6= r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\37. New DP Data\\BPO_PEOPLE\"\n",
    "path7= r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\37. New DP Data\\MODERATION_STATS\"\n",
    "path8= r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\37. New DP Data\\MODERATION_STATS_HOUR\"\n",
    "path9 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Labeling\\Single Moderation\"\n",
    "path10 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Ads_productivity_v2\"\n",
    "path12 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Ads_Efficiency\"\n",
    "path11 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Ads_Quality_QA_Mode\"\n",
    "path16 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Ads_status\"\n",
    "path17 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\19. MMP Data Calibration - Aux Codes\"\n",
    "path18 = r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\9. Quality Data\\AVIA\"\n",
    "path19 = r\"//emea.tpg.ads/portugal/Departments/ITDEV/PowerBI/accounting/business analysts/01 - ba/02 - projects/tiktok/4. Raw Data and Aux Files/9. Quality Data/UNO Project/Final_version\"\n",
    "path20 = r\"//emea.tpg.ads/portugal/Departments/ITDEV/PowerBI/accounting/business analysts/01 - ba/02 - projects/tiktok/4. Raw Data and Aux Files/9. Quality Data\\UNO Project\\UNO Random Sampling\\Final_version\"\n",
    "path21 =  r\"//emea.tpg.ads/portugal/Departments/ITDEV/PowerBI/accounting/business analysts/01 - ba/02 - projects/tiktok/4. Raw Data and Aux Files/9. Quality Data\\GA Sampling_new\\Final_version\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d12826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path26\n",
    "list_of_paths = [path1, path4,path2,path6, path7,path8,path9,\n",
    "                 path10, path11,path12,path16,path19,path20,path21] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065aab55",
   "metadata": {},
   "source": [
    "# Today's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361da9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_columns = []\n",
    "path_id = []\n",
    "columns_types = []\n",
    "\n",
    "#ref: https://stackoverflow.com/questions/39327032/how-to-get-the-latest-file-in-a-folder\n",
    "\n",
    "path4_latest = max(glob.glob(path4+'/*'), key=os.path.getmtime)\n",
    "path4_df = pd.read_csv(path4_latest, skiprows=1, index_col=False)\n",
    "number_of_columns.append(path4_df.shape[1])\n",
    "path_id.append(path4_latest)\n",
    "columns_types.append((list(path4_df.columns), list(path4_df.dtypes)))\n",
    "\n",
    "\n",
    "for path in list_of_paths:\n",
    "    list_of_files = glob.glob(path+'/*')\n",
    "    latest_file = max(list_of_files, key=os.path.getmtime)\n",
    "    \n",
    "    if fnmatch.fnmatch(latest_file, '*.xlsx'):\n",
    "        paths_df = pd.read_excel(latest_file)\n",
    "        number_of_columns.append(paths_df.shape[1])\n",
    "        path_id.append(latest_file)\n",
    "        columns_types.append((list(paths_df.columns), list(paths_df.dtypes)))\n",
    "        \n",
    "    else:\n",
    "        paths_df = pd.read_csv(latest_file)\n",
    "        number_of_columns.append(paths_df.shape[1])\n",
    "        path_id.append(latest_file)\n",
    "        columns_types.append((list(paths_df.columns), list(paths_df.dtypes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df04f0",
   "metadata": {},
   "source": [
    "# Oldest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d249ee2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_columns_old = []\n",
    "path_id_old = []\n",
    "columns_types_old = []\n",
    "\n",
    "#ref: https://stackoverflow.com/questions/39327032/how-to-get-the-latest-file-in-a-folder\n",
    "path4_old = sorted(glob.glob(path4+'/*'), key=os.path.getmtime)[-4]\n",
    "path4_old_df = pd.read_csv(path4_old, skiprows=1, index_col=False)\n",
    "number_of_columns_old.append(path4_old_df.shape[1])\n",
    "path_id_old.append(path4_old)\n",
    "columns_types_old.append((list(path4_old_df.columns), list(path4_old_df.dtypes)))\n",
    "\n",
    "\n",
    "\n",
    "for path in list_of_paths:\n",
    "    #list_of_files = sorted(glob.glob(path+'/*'), key=os.path.getmtime)[-2]\n",
    "    file_old = sorted(glob.glob(path+'/*'), key=os.path.getmtime)[-4]\n",
    "\n",
    "    if fnmatch.fnmatch(file_old, '*.xlsx'):\n",
    "        paths_old_df = pd.read_excel(file_old)\n",
    "        number_of_columns_old.append(paths_old_df.shape[1])\n",
    "        path_id_old.append(file_old)\n",
    "        columns_types_old.append((list(paths_old_df.columns), list(paths_old_df.dtypes)))\n",
    "        \n",
    "    else:\n",
    "        paths_old_df = pd.read_csv(file_old)\n",
    "        number_of_columns_old.append(paths_old_df.shape[1])\n",
    "        path_id_old.append(file_old)\n",
    "        columns_types_old.append((list(paths_old_df.columns), list(paths_old_df.dtypes)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e550f87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_numbers_comparisons = pd.DataFrame(data ={'file': path_id,\n",
    "                                                 'today': number_of_columns,\n",
    "                                                 'oldest':number_of_columns_old\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc14789c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_numbers_comparisons['file'] = column_numbers_comparisons['file'].str.replace(\"\\\\\", \" \")\n",
    "column_numbers_comparisons['file'] = column_numbers_comparisons['file'].str.replace(\"  emea.tpg.ads portugal Departments ITDEV PowerBI accounting business analysts 01 - ba 02 - projects tiktok 4. Raw Data and Aux Files\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c6c4e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>today</th>\n",
       "      <th>oldest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37. New DP Data BPO_QUEUE_VMS LatSLA_VMS_06082024_13082024.csv</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37. New DP Data BPO_QUEUE_DAILY LatSLA_06082024_13082024.csv</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37. New DP Data BPO_QUEUE_VMS LatSLA_VMS_06082024_13082024.csv</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37. New DP Data INTEGRITY Integrity_MI_01082024_15082024.csv</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37. New DP Data BPO_PEOPLE WorkHour Indicators 29072024_31072024.csv</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37. New DP Data MODERATION_STATS global_moderation_stat_01082024_15082024.csv</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37. New DP Data MODERATION_STATS_HOUR hour_global_moderation_stat_06082024_09082024.csv</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10. MI Labeling Single Moderation _Labelling Project Details - Single Mod - 01072024_31072024.csv</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10. MI Ads_productivity_v2 Productivity Raw Data_20240805_20240811.csv</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. MI Ads_Quality_QA_Mode _QA Mode - RAW data - task level_20240701_20240731.csv</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10. MI Ads_Efficiency AdsReview_RawData-29072024_04082024.csv</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10. MI Ads_status Statuses Raw Data_22072024_28072024.csv</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>//emea.tpg.ads/portugal/Departments/ITDEV/PowerBI/accounting/business analysts/01 - ba/02 - projects/tiktok/4. Raw Data and Aux Files/9. Quality Data/UNO Project/Final_version UNO_Moderator Error Case Picker_2024 W30.csv</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>//emea.tpg.ads/portugal/Departments/ITDEV/PowerBI/accounting/business analysts/01 - ba/02 - projects/tiktok/4. Raw Data and Aux Files/9. Quality Data UNO Project UNO Random Sampling Final_version UNO_Moderator Error Case Picker_2024 W13.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>//emea.tpg.ads/portugal/Departments/ITDEV/PowerBI/accounting/business analysts/01 - ba/02 - projects/tiktok/4. Raw Data and Aux Files/9. Quality Data GA Sampling_new Final_version QA_Case Picker - Simulation  - 2024 W31.csv</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                file  \\\n",
       "0                                                                                                                                                                                     37. New DP Data BPO_QUEUE_VMS LatSLA_VMS_06082024_13082024.csv   \n",
       "1                                                                                                                                                                                       37. New DP Data BPO_QUEUE_DAILY LatSLA_06082024_13082024.csv   \n",
       "2                                                                                                                                                                                     37. New DP Data BPO_QUEUE_VMS LatSLA_VMS_06082024_13082024.csv   \n",
       "3                                                                                                                                                                                       37. New DP Data INTEGRITY Integrity_MI_01082024_15082024.csv   \n",
       "4                                                                                                                                                                               37. New DP Data BPO_PEOPLE WorkHour Indicators 29072024_31072024.csv   \n",
       "5                                                                                                                                                                      37. New DP Data MODERATION_STATS global_moderation_stat_01082024_15082024.csv   \n",
       "6                                                                                                                                                            37. New DP Data MODERATION_STATS_HOUR hour_global_moderation_stat_06082024_09082024.csv   \n",
       "7                                                                                                                                                  10. MI Labeling Single Moderation _Labelling Project Details - Single Mod - 01072024_31072024.csv   \n",
       "8                                                                                                                                                                             10. MI Ads_productivity_v2 Productivity Raw Data_20240805_20240811.csv   \n",
       "9                                                                                                                                                                  10. MI Ads_Quality_QA_Mode _QA Mode - RAW data - task level_20240701_20240731.csv   \n",
       "10                                                                                                                                                                                     10. MI Ads_Efficiency AdsReview_RawData-29072024_04082024.csv   \n",
       "11                                                                                                                                                                                         10. MI Ads_status Statuses Raw Data_22072024_28072024.csv   \n",
       "12                      //emea.tpg.ads/portugal/Departments/ITDEV/PowerBI/accounting/business analysts/01 - ba/02 - projects/tiktok/4. Raw Data and Aux Files/9. Quality Data/UNO Project/Final_version UNO_Moderator Error Case Picker_2024 W30.csv   \n",
       "13  //emea.tpg.ads/portugal/Departments/ITDEV/PowerBI/accounting/business analysts/01 - ba/02 - projects/tiktok/4. Raw Data and Aux Files/9. Quality Data UNO Project UNO Random Sampling Final_version UNO_Moderator Error Case Picker_2024 W13.csv   \n",
       "14                   //emea.tpg.ads/portugal/Departments/ITDEV/PowerBI/accounting/business analysts/01 - ba/02 - projects/tiktok/4. Raw Data and Aux Files/9. Quality Data GA Sampling_new Final_version QA_Case Picker - Simulation  - 2024 W31.csv   \n",
       "\n",
       "    today  oldest  \n",
       "0      16      16  \n",
       "1      27      27  \n",
       "2      16      16  \n",
       "3      12      12  \n",
       "4      17      17  \n",
       "5      26      26  \n",
       "6      21      21  \n",
       "7      17      17  \n",
       "8      11      11  \n",
       "9      40      40  \n",
       "10     33      33  \n",
       "11     31      31  \n",
       "12     31      31  \n",
       "13     19      19  \n",
       "14     30      30  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_numbers_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf46dc4a",
   "metadata": {},
   "source": [
    "### Check the number of columns that are different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80751e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(column_numbers_comparisons.file)):\n",
    "    if column_numbers_comparisons.today[i] != column_numbers_comparisons.oldest[i]:\n",
    "        print(column_numbers_comparisons.file[i], '\\nDifferent columns:', \n",
    "                 abs(column_numbers_comparisons.today[i] - column_numbers_comparisons.oldest[i]), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f72e0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.DataFrame.from_dict(\n",
    "    dict(zip(path_id, columns_types))\\\n",
    "            ).transpose().reset_index().rename(\\\n",
    "                    columns = {'index': 'File_today', 0: 'Columns_new', 1:'Dtypes_new'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9676857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o = pd.DataFrame.from_dict(\n",
    "    dict(zip(path_id_old, columns_types_old))\\\n",
    "            ).transpose().reset_index().rename(\\\n",
    "                    columns = {'index': 'File_old', 0: 'Columns_old', 1:'Dtypes_old'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5edd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.merge(df_n, df_o)[['File_today', 'File_old', 'Columns_new', 'Columns_old', 'Dtypes_new', 'Dtypes_old']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c160b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X['File_today'] = df_X['File_today'].str.replace(\"\\\\\", \" \")\n",
    "df_X['File_today'] = df_X['File_today'].str.replace(\"  emea.tpg.ads portugal Departments ITDEV PowerBI accounting business analysts 01 - ba 02 - projects tiktok 4. Raw Data and Aux Files\", \"\")\n",
    "df_X['File_old'] = df_X['File_old'].str.replace(\"\\\\\", \" \")\n",
    "df_X['File_old'] = df_X['File_old'].str.replace(\"  emea.tpg.ads portugal Departments ITDEV PowerBI accounting business analysts 01 - ba 02 - projects tiktok 4. Raw Data and Aux Files\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c372fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X['similar_names'] = df_X['Columns_new'] == df_X['Columns_old']\n",
    "df_X['similar_dtypes'] = df_X['Dtypes_new'] == df_X['Dtypes_old']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b10f6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_X[['File_today', 'File_old', 'Columns_new', 'Columns_old', 'similar_names', 'Dtypes_new',\n",
    "       'Dtypes_old', 'similar_dtypes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a37f08",
   "metadata": {},
   "source": [
    "### (Most Important) Check the names of columns that are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37f1ca4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(df_X[df_X['similar_names'] == False].shape[0]):\n",
    "    a = list(set(list(df_X[df_X['similar_names'] == False]['Columns_old'])[i]).symmetric_difference(\n",
    "        set(list(df_X[df_X['similar_names'] == False]['Columns_new'])[i])))\n",
    "    b = list(df_X[df_X['similar_names'] == False]['File_today'])[i]\n",
    "    c = list(df_X[df_X['similar_names'] == False]['File_old'])[i]\n",
    "    \n",
    "    print('Different columns between files \\n', b, '\\nand\\n', c, '\\nare:\\n\\n', a, \n",
    "          '\\n---------------------------------------------------------------------\\\n",
    "----------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5133d9ba",
   "metadata": {},
   "source": [
    "### Check the datatypes that are different and their corresponding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "879c94c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(df_X[df_X['similar_dtypes'] == False].shape[0]):\n",
    "    a = list(set([str(i+1) + ' ' + str(j) for i, j in \n",
    "                  enumerate(list(df_X[df_X['similar_dtypes'] == \n",
    "                                      False]['Dtypes_new'])[i])]).symmetric_difference(\n",
    "        set([str(i+1) + ' ' + str(j) for i, j \n",
    "             in enumerate(list(df_X[df_X['similar_dtypes'] == False]['Dtypes_old'])[i])])))\n",
    "\n",
    "    b = list(df_X[df_X['similar_dtypes'] == False]['File_today'])[i]\n",
    "    c = list(df_X[df_X['similar_dtypes'] == False]['File_old'])[i]\n",
    "    \n",
    "    d = dict(zip([str(i+1) + ' ' + str(j) for i, j in enumerate(\n",
    "        list(df_X[df_X['similar_dtypes'] == False]['Dtypes_new'])[i])],\n",
    "         [str(i+1) + ' ' + str(j) for i, j in enumerate(\n",
    "             list(df_X[df_X['similar_dtypes'] == False]['Columns_new'])[i])]))\n",
    "    e = []\n",
    "    for k, v in d.items():\n",
    "        if k in a:\n",
    "            e.append(v)\n",
    "    \n",
    "#print('Different data types between files \\n', b, '\\nand\\n', c, '\\nare:\\n\\n', a, '\\n', e,\n",
    "          #'\\n-------------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3ff0b",
   "metadata": {},
   "source": [
    "# The bellow code will verify duplication of data on the file listed on folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57b1742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders={\n",
    "\n",
    "    'Mi Labeling': r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Labeling\\Single Moderation\",\n",
    "    'Mi status':r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Ads_status\",\n",
    "    'Ads_Review':r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Ads_Efficiency\",\n",
    "    'Ads_Ads_productivity_v2':r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Ads_productivity_v2\",\n",
    "    'Ads_Mode':r\"\\\\emea.tpg.ads\\portugal\\Departments\\ITDEV\\PowerBI\\accounting\\business analysts\\01 - ba\\02 - projects\\tiktok\\4. Raw Data and Aux Files\\10. MI\\Ads_Quality_QA_Mode\"\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e015622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In folder Mi Labeling, no duplicate dates were found among the files.\n",
      "In folder Mi status, no duplicate dates were found among the files.\n",
      "In folder Ads_Review, no duplicate dates were found among the files.\n",
      "In folder Ads_Ads_productivity_v2, no duplicate dates were found among the files.\n",
      "In folder Ads_Mode, no duplicate dates were found among the files.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#7 Group\n",
    "#THIS CODE WILL VERIFY EACH FOLDER AND EACH FILE AND GRAB AL THE DATES AND DO A UNIQUE DATE,\n",
    "#IN CASE 2 FILE WILL HAVE THE SAME DATE THAT FILE AND DATE WILL BE SHOW ON THE CODE RESULT.\n",
    "def check_duplicate_dates_in_folder(folder_path):\n",
    "    # List all files in the folder\n",
    "    files = sorted(os.listdir(folder_path), key=lambda x: os.path.getmtime(os.path.join(folder_path, x)), reverse=True)[:5]\n",
    "    # Create a dictionary to store unique dates from each file\n",
    "    unique_dates_dict = {}\n",
    "    # Iterate over the files\n",
    "    for file in files:\n",
    "        # Check if the file is a regular file (not a directory)\n",
    "        if os.path.isfile(os.path.join(folder_path, file)):\n",
    "            # Read the file content into a pandas DataFrame\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)  # Assuming files are in CSV format, adjust the format as needed\n",
    "                # Check if the 'Date' or 'Hour' column exists in the DataFrame\n",
    "                date_column = None\n",
    "                if 'QA1 Date' in df.columns:\n",
    "                    date_column = df['QA1 Date']\n",
    "                elif 'operate_date' in df.columns:\n",
    "                    date_column = df['operate_date']\n",
    "                elif 'resolve_date' in df.columns:\n",
    "                    date_column = df['resolve_date']\n",
    "                elif 'duty_date'in df.columns:\n",
    "                    date_column = df['duty_date']\n",
    "                elif 'QA Date' in df.columns:\n",
    "                    date_column = df['QA Date']\n",
    "                elif 'p_date' in df.columns:\n",
    "                    date_column = df['p_date']\n",
    "                else:\n",
    "                    raise ValueError(f\"Any date coluns found based on the if condition: {file_path}\")\n",
    "                # Convert the date column to datetime\n",
    "                df['Date'] = pd.to_datetime(date_column, errors='coerce')\n",
    "                # Remove rows with invalid dates\n",
    "                df = df.dropna(subset=['Date'])\n",
    "                # Add unique dates to the dictionary\n",
    "                unique_dates_dict[file] = set(df['Date'].unique())\n",
    "            except pd.errors.EmptyDataError:\n",
    "                pass  # Ignore empty files\n",
    "            \n",
    "    # Compare unique dates across all files to find duplicate dates\n",
    "    duplicate_dates = set()\n",
    "    for file1, dates1 in unique_dates_dict.items():\n",
    "        for file2, dates2 in unique_dates_dict.items():\n",
    "            if file1 != file2 and dates1 & dates2:\n",
    "                duplicate_dates.update(dates1 & dates2)\n",
    "\n",
    "    return duplicate_dates\n",
    "\n",
    "for short_name, folder_path in folders.items():\n",
    "    duplicate_dates = check_duplicate_dates_in_folder(folder_path)\n",
    "    if duplicate_dates:\n",
    "        print(f'In folder {short_name}, the following dates are duplicated in at least two files: {duplicate_dates}.')\n",
    "    else:\n",
    "        print(f'In folder {short_name}, no duplicate dates were found among the files.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced93a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc4080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2726f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
